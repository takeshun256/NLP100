{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello NLP100\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello NLP100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 文字列の逆順"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "s = \"stressed\"\n",
    "print(s[::-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 パタとくかシーー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー\n"
     ]
    }
   ],
   "source": [
    "s = \"パタトクカシーー\"\n",
    "print(s[::2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 「パトカー」＋「タクシー」＝「パタトクカシーー」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー"
     ]
    }
   ],
   "source": [
    "s1 = \"パトカー\"\n",
    "s2 = \"タクシー\"\n",
    "for i in range(len(s1)):\n",
    "    print(s1[i] + s2[i], end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 円周率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314159265358979"
     ]
    }
   ],
   "source": [
    "s = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "s = re.sub(r\"[,.]\", \"\", s)\n",
    "s_sp = s.split(\" \")\n",
    "for i in s_sp:\n",
    "    print(len(i), end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 元素記号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 0, 'He': 1, 'Li': 2, 'Be': 3, 'B': 4, 'C': 5, 'N': 6, 'O': 7, 'F': 8, 'Ne': 9, 'Na': 10, 'Mi': 11, 'Al': 12, 'Si': 13, 'P': 14, 'S': 15, 'Cl': 16, 'Ar': 17, 'K': 18, 'Ca': 19}\n"
     ]
    }
   ],
   "source": [
    "s = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "s = re.sub(r\"[,.]\", \"\", s)\n",
    "s_sp = s.split(\" \")\n",
    "\n",
    "taked_one = [1, 5, 6, 7, 8, 9, 15, 16, 19]\n",
    "dic = {}\n",
    "\n",
    "for i in range(len(s_sp)):\n",
    "    if i+1 in taked_one:\n",
    "        dic[s_sp[i][0]] = i\n",
    "    else:\n",
    "        dic[s_sp[i][0:2]] = i\n",
    "\n",
    "print(dic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "単語bi-gram ['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n",
      "文字bi-gram [['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n"
     ]
    }
   ],
   "source": [
    "def make_n_gram(n, s):\n",
    "    return [s[i:i+n] for i in range(len(s)-n+1)]\n",
    "\n",
    "\n",
    "print(\"文字bi-gram\", make_n_gram(2, \"I am an NLPer\"))\n",
    "print(\"単語bi-gram\", make_n_gram(2, \"I am an NLPer\".split(\" \")))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  06 集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和集合 {'se', 'gr', 'ad', 'ar', 'di', 'is', 'pa', 'ag', 'ph', 'ap', 'ra'}\n",
      "積集合 {'ra', 'ar', 'ap', 'pa'}\n",
      "差集合 {'se', 'di', 'ad', 'is'}\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "X = set(make_n_gram(2, \"paraparaparadise\"))\n",
    "Y = set(make_n_gram(2, \"paragraph\"))\n",
    "\n",
    "\n",
    "print(\"和集合\", X | Y)\n",
    "print(\"積集合\", X & Y)\n",
    "print(\"差集合\", X - Y)\n",
    "\n",
    "print(\"se\" in X)\n",
    "print(\"se\" in Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07 テンプレートによる文生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n",
      "零時の湿度は60\n"
     ]
    }
   ],
   "source": [
    "def make_sentence(x, y, z):\n",
    "    return f\"{x}時の{y}は{z}\"\n",
    "\n",
    "print(make_sentence(x=12, y=\"気温\", z=22.4))\n",
    "print(make_sentence(x=\"零\", y=\"湿度\", z=60))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08 暗号文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I zn zm NLPvi\n",
      "I am an NLPer\n"
     ]
    }
   ],
   "source": [
    "def cipher(s):\n",
    "    return \"\".join([chr(219-ord(i)) if i.islower() else i for i in s])\n",
    "\n",
    "print(cipher(\"I am an NLPer\")) # 暗号化\n",
    "print(cipher(cipher(\"I am an NLPer\"))) # 復号化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09 Typoglycemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I codnl’ut bilevee that I cloud altcualy udntsarned what I was rdneaig : the pnenhmoeal power of the haumn mind .\n",
      "I clnud’ot beevlie that I cuold alctaluy unedsatnrd what I was radenig : the pnhmaoneel pwoer of the human mind .\n",
      "I cul’nodt bieelve that I cluod alcltuay uarndenstd what I was rindaeg : the penoemnhal power of the hamun mind .\n"
     ]
    }
   ],
   "source": [
    "def typoglycemia(s):\n",
    "    s_sp = s.split(\" \")\n",
    "    for i, ss in enumerate(s_sp):\n",
    "        if len(ss) > 4:\n",
    "            s_sp[i] = ss[0] + \"\".join(random.sample(ss[1:-1], len(ss)-2)) + ss[-1]\n",
    "    return \" \".join(s_sp)\n",
    "\n",
    "s = \"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "print(typoglycemia(s))\n",
    "print(typoglycemia(s))\n",
    "print(typoglycemia(s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所感"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n-gramは、文字単位や単語単位でのn-gramがある\n",
    "- リストのスライスの何ごとの設定も重要である。\n",
    "- n-gramの関数はいろんなところで使えそう\n",
    "- chrとordの使い分けがわかった。\n",
    "- リストのスライス操作で、いろんな前処理ができることがわかった。\n",
    "- splitとjoinが対応関係になっている\n",
    "- reライブラリによる、正規表現処理が苦手かも"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
